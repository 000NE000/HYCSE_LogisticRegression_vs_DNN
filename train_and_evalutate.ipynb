{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66cca6b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ef164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Trains the model for one epoch.\n",
    "    Args:\n",
    "      - model: The neural network model.\n",
    "      - dataloader: DataLoader providing the training data.\n",
    "      - criterion: Loss function (BCEWithLogitsLoss) which handles both sigmoid and BCE.\n",
    "      - optimizer: Adam optimizer with L2 regularization (weight_decay).\n",
    "      - device: 'cpu' or 'cuda' (if GPU is available).\n",
    "\n",
    "    Returns:\n",
    "      - avg_loss: The average training loss over the epoch.\n",
    "    \"\"\"\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    # [batch gradient decent]\n",
    "    for inputs, targets in dataloader: # Each iteration retrieves a batch of images (inputs) and their labels (targets).\n",
    "        # Move data to the designated device\n",
    "        inputs, targets = inputs.to(device), targets.to(device).float().unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, targets)  # Compute loss\n",
    "\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update model parameters\n",
    "\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        # Convert logits to probability using Sigmoid, then classify with threshold 0.5\n",
    "        preds = (torch.sigmoid(outputs) >= 0.5).float()\n",
    "        correct_predictions += (preds == targets).sum().item()\n",
    "    avg_loss = running_loss / len(dataloader.dataset)\n",
    "    accuracy = correct_predictions / len(dataloader.dataset)\n",
    "    print(\"Returning from evaluate_model:\", avg_loss, accuracy)\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bc2976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the given data loader.\n",
    "\n",
    "    Args:\n",
    "      - model: The trained model.\n",
    "      - dataloader: DataLoader providing the evaluation data.\n",
    "      - criterion: Loss function.\n",
    "      - device: 'cpu' or 'cuda'.\n",
    "\n",
    "    Returns:\n",
    "      - avg_loss: The average evaluation loss.\n",
    "      - accuracy: Proportion of correct predictions.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mo     de\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad(): #for memory conservation . it disables GD\n",
    "        for inputs, targets in dataloader:\n",
    "\n",
    "            # Move to the appropriate device\n",
    "            inputs = inputs.to(device)\n",
    "            # For binary labels, ensure targets shape is consistent: [batch_size, 1]\n",
    "            targets = targets.to(device).float().unsqueeze(1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Convert logits to probability using Sigmoid, then classify with threshold 0.5\n",
    "            preds = (torch.sigmoid(outputs) >= 0.5).float()\n",
    "            correct_predictions += (preds == targets).sum().item()\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader.dataset)\n",
    "    accuracy = correct_predictions / len(dataloader.dataset)\n",
    "    print(\"Returning from evaluate_model, average_loss\", avg_loss, \"accracy : \", accuracy)\n",
    "    return avg_loss, accuracy"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
