{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f86a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # For file and path handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b406f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch  # For tensors, generators, etc.\n",
    "from torch.utils.data import DataLoader, random_split  # For data loading/splitting\n",
    "from torchvision import datasets, transforms  # For image datasets and transformations\n",
    "from LR import LR\n",
    "from DNN import DNN, train_one_epoch, train_model_with_early_stopping, evaluate_model\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from train_and_evalutate import train_model, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e99fe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.expanduser(\"../chest_xray\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1), #Converts RGB images to 1-channel grayscale\n",
    "    transforms.Resize ((128, 128)), #Resizes all images to 128x128 pixels\n",
    "    transforms.ToTensor(), #Converts the PIL image (0–255) to a PyTorch tensor (0–1) and adds a channel dimension (C×H×W).\n",
    "    # transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e360f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 128 * 128 #Calculates the flattened input dimension for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ef9a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_ds = datasets.ImageFolder(os.path.join(root_dir, 'train'), transform=transform)\n",
    "test_ds = datasets.ImageFolder(os.path.join(root_dir, 'test'), transform=transform)\n",
    "train_size = int(0.8 * len(trainval_ds))\n",
    "val_size = len(trainval_ds) - train_size\n",
    "train_ds, val_ds = random_split(trainval_ds, [train_size, val_size], generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f539551",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader (train_ds, batch_size=32, shuffle=True) #Creates a DataLoader for the training set B = 32\n",
    "val_loader = DataLoader(val_ds, batch_size=32) #Validation DataLoader (no shuffling, deterministic evaluation)\n",
    "test_loader = DataLoader (test_ds, batch_size=32) #Test DataLoader (used during final model evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f1b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab0c775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b062eed7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aded1ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Sample hyperparameters\n",
    "    hidden_dim1 = trial.suggest_int(\"hidden_dim1\", 256, 1024)\n",
    "    hidden_dim2 = trial.suggest_int(\"hidden_dim2\", 128, hidden_dim1)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log=True)\n",
    "\n",
    "    # Set layer dimensions: [input_dim, hidden_dim1, hidden_dim2]\n",
    "    layer_dims = [input_dim, hidden_dim1, hidden_dim2]\n",
    "\n",
    "    # Create the model and move it to the device\n",
    "    model = DNN(layer_dims, dropout_rate=dropout_rate).to(device)\n",
    "\n",
    "    # Define the loss function\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Set up the optimizer with the sampled hyperparameters\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # Train the model for a few epochs for quick tuning (e.g., 5 epochs)\n",
    "    num_epochs = 27\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, _ = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "\n",
    "    # Evaluate on the validation set\n",
    "    val_loss, _ = evaluate_model(model, val_loader, criterion, device)\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006f5e05",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Run the optimization (number of trials can be adjusted)\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "print(\"Starting hyperparameter optimization with Optuna...\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "print(\"============================================================\")\n",
    "print(\"Best hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c520c57",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'hidden_dim1': 939,\n",
    "    'hidden_dim2': 799,\n",
    "    'dropout_rate': 0.2963617429089822,\n",
    "    'learning_rate': 0.002844883832313113,\n",
    "    'weight_decay': 1.2973725923247895e-05\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e907354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the final model using the best hyperparameters from Optuna\n",
    "layer_dims_final = [input_dim, best_params[\"hidden_dim1\"], best_params[\"hidden_dim2\"]]\n",
    "final_model = DNN(layer_dims_final, dropout_rate=best_params[\"dropout_rate\"]).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(final_model.parameters(), lr=best_params[\"learning_rate\"], weight_decay=best_params[\"weight_decay\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3f6f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model for the full experiment epochs using early stopping\n",
    "experiment_epoch = [2, 10, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8081a83a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "for num_epochs in experiment_epoch:\n",
    "    ######################################\n",
    "    #                   LR               #\n",
    "    ######################################\n",
    "    lr_instance = LR(input_dim, train_loader, val_loader, test_loader)\n",
    "    acc_LR_train, acc_LR_val = lr_instance.train_LR(num_epochs, save_path='model_LR.pth')\n",
    "    _, acc_LR_test = lr_instance.evaluate_LR(save_path='model_LR.pth')\n",
    "\n",
    "    ######################################\n",
    "    #                DNN                 #\n",
    "    ######################################\n",
    "    best_model_final, DNN_train_acc, DNN_val_acc = train_model_with_early_stopping(\n",
    "        final_model, train_loader, val_loader, criterion, optimizer,\n",
    "        num_epochs=num_epochs, device=device, patience=4\n",
    "    )\n",
    "    _, DNN_test_acc = evaluate_model(best_model_final, test_loader, criterion, device)\n",
    "\n",
    "    ######################################\n",
    "    #         PLOTTING RESULTS           #\n",
    "    ######################################\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    LR_results = ['LR_train', 'LR_val', 'LR_test']\n",
    "    LR_accuracies = [acc_LR_train, acc_LR_val, acc_LR_test]\n",
    "\n",
    "    DNN_results = ['DNN train', 'DNN val', 'DNN test']\n",
    "    DNN_accuracies = [DNN_train_acc, DNN_val_acc, DNN_test_acc]\n",
    "\n",
    "    plt.bar(LR_results, LR_accuracies)\n",
    "    plt.bar(DNN_results, DNN_accuracies)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Model Accuracy Comparison')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
